{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter](https://arxiv.org/abs/1910.01108)\n",
    "\n",
    "In this lecture, we will explore the architecture of DistilBERT, its key components, and how it can be utilized for various natural language processing tasks. Additionally, we'll discuss its advantages, limitations, and provide hands-on examples to showcase its effectiveness.\n",
    "\n",
    "Reference : [The Theory](https://towardsdatascience.com/distillation-of-bert-like-models-the-code-73c31e8c2b0a) | [Code](https://towardsdatascience.com/distillation-of-bert-like-models-the-theory-32e19a02641f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install datasets --upgrade\n",
    "import datasets\n",
    "import transformers\n",
    "import torch\n",
    "datasets.__version__, transformers.__version__, torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "import random, math, time\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "#make our work comparable if restarted the kernel\n",
    "SEED = 1234\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading our MNLI part of the GLUE dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import datasets\n",
    "\n",
    "###1. Load Dataset\n",
    "task_to_keys = {\n",
    "    \"cola\": (\"sentence\", None),\n",
    "    \"mnli\": (\"premise\", \"hypothesis\"),\n",
    "    \"mrpc\": (\"sentence1\", \"sentence2\"),\n",
    "    \"qnli\": (\"question\", \"sentence\"),\n",
    "    \"qqp\": (\"question1\", \"question2\"),\n",
    "    \"rte\": (\"sentence1\", \"sentence2\"),\n",
    "    \"sst2\": (\"sentence\", None),\n",
    "    \"stsb\": (\"sentence1\", \"sentence2\"),\n",
    "    \"wnli\": (\"sentence1\", \"sentence2\"),\n",
    "}\n",
    "\n",
    "task_name = \"mnli\"\n",
    "raw_datasets = datasets.load_dataset(\"glue\", task_name)\n",
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = raw_datasets['train'].features['label'].names\n",
    "label2id = {v: i for i, v in enumerate(label_list)}\n",
    "label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {i: v for v, i in label2id.items()}\n",
    "id2label"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model & Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "num_labels = np.unique(raw_datasets['train']['label']).size\n",
    "num_labels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"figures/BERT_embed.png\" width=500>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "teacher_id = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(teacher_id)\n",
    "\n",
    "teacher_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    teacher_id, \n",
    "    num_labels = num_labels,\n",
    "    id2label = id2label,\n",
    "    label2id = label2id,\n",
    ")\n",
    "\n",
    "teacher_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    sentence1_key, sentence2_key = task_to_keys[task_name]\n",
    "    args = (\n",
    "        (examples[sentence1_key],) if sentence2_key is None else (examples[sentence1_key], examples[sentence2_key])\n",
    "    )\n",
    "    result = tokenizer(*args, max_length=128, truncation=True)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(task_to_keys[task_name])\n",
    "column_dataset = [item for item in task_to_keys[task_name] if item is not None]\n",
    "column_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove column : 'premise', 'hypothesis', 'idx'\n",
    "tokenized_datasets = tokenized_datasets.remove_columns(column_dataset + [\"idx\"])\n",
    "#rename column : 'labels'\n",
    "tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
    "tokenized_datasets.set_format(\"torch\")\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets['train'][0]['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(tokenized_datasets['train'][0]['input_ids'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Preparing the dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "#Data collator that will dynamically pad the inputs received."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=1150).select(range(10000))\n",
    "small_eval_dataset = tokenized_datasets[\"validation_mismatched\"].shuffle(seed=1150).select(range(1000))\n",
    "small_test_dataset = tokenized_datasets[\"test_mismatched\"].shuffle(seed=1150).select(range(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_dataloader = DataLoader(\n",
    "    small_train_dataset, shuffle=True, batch_size=32, collate_fn=data_collator)\n",
    "test_dataloader = DataLoader(\n",
    "    small_test_dataset, batch_size=32, collate_fn=data_collator)\n",
    "eval_dataloader = DataLoader(\n",
    "    small_eval_dataset, batch_size=32, collate_fn=data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_dataloader:\n",
    "    break\n",
    "    \n",
    "batch['labels'].shape, batch['input_ids'].shape, batch['attention_mask'].shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Design the model and losses"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Teacher Model & Student Model\n",
    "\n",
    "####  Architecture \n",
    "In the present work, the student - DistilBERT - has the same general architecture as BERT. \n",
    "- The `token-type embeddings` and the `pooler` are removed while `the number of layers` is reduced by a factor of 2. \n",
    "- Most of the operations used in the Transformer architecture `linear layer` and `layer normalisation` are highly optimized in modern linear algebra frameworks.\n",
    "- our investigations showed that variations on the last dimension of the tensor (hidden size dimension) have a smaller impact on computation efficiency (for a fixed parameters budget) than variations on other factors like the number of layers. \n",
    "- Thus we focus on reducing the number of layers.\n",
    "\n",
    "#### Initialize Student Model\n",
    "- To initialize a new model from an existing one, we need to access the weights of the old model (the teacher). \n",
    "- In order to get the weights, we first have to know how to access them. Weâ€™ll use BERT as our teacher model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_model.config"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \n",
    "- The student model has the same configuration, except the number of layers is reduced by a factor of 2\n",
    "- The student layers are initilized by copying one out of two layers of the teacher, starting with layer 0.\n",
    "- The head of the teacher is also copied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.models.bert.modeling_bert import BertPreTrainedModel, BertConfig\n",
    "# Get teacher configuration as a dictionnary\n",
    "configuration = teacher_model.config.to_dict()\n",
    "# configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Half the number of hidden layer\n",
    "configuration['num_hidden_layers'] //= 2\n",
    "# Convert the dictionnary to the student configuration\n",
    "configuration = BertConfig.from_dict(configuration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create uninitialized student model\n",
    "model = type(teacher_model)(configuration)\n",
    "model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Recursively copies the weights of the (teacher) to the (student).\n",
    "- This function is meant to be first called on a BertFor... model, but is then called on every children of that model recursively.\n",
    "- The only part that's not fully copied is the encoder, of which only half is copied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.models.bert.modeling_bert import BertEncoder, BertModel\n",
    "from torch.nn import Module\n",
    "\n",
    "def distill_bert_weights(\n",
    "    teacher : Module,\n",
    "    student : Module,\n",
    "    init_method : str\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Recursively copies the weights of the (teacher) to the (student).\n",
    "    This function is meant to be first called on a BertFor... model, but is then called on every children of that model recursively.\n",
    "    The only part that's not fully copied is the encoder, of which only half is copied.\n",
    "    \"\"\"\n",
    "    # If the part is an entire BERT model or a BERTFor..., unpack and iterate\n",
    "    if isinstance(teacher, BertModel) or type(teacher).__name__.startswith('BertFor'):\n",
    "        for teacher_part, student_part in zip(teacher.children(), student.children()):\n",
    "            distill_bert_weights(teacher_part, student_part, init_method)\n",
    "    # Else if the part is an encoder, copy one out of every layer\n",
    "    elif isinstance(teacher, BertEncoder):\n",
    "        teacher_encoding_layers = [layer for layer in next(teacher.children())] #12 layers\n",
    "        student_encoding_layers = [layer for layer in next(student.children())] #6 layers\n",
    "\n",
    "        if init_method == 'Top-K Layer':\n",
    "            for i in range(len(student_encoding_layers)):\n",
    "                student_encoding_layers[i].load_state_dict(teacher_encoding_layers[i].state_dict())\n",
    "\n",
    "        elif init_method == 'Bottom-K Layer':\n",
    "            for i in range(len(student_encoding_layers)):\n",
    "                student_encoding_layers[i].load_state_dict(teacher_encoding_layers[i+len(student_encoding_layers)].state_dict())\n",
    "\n",
    "        elif init_method == 'Odd Layer':\n",
    "            for i in range(len(student_encoding_layers)):\n",
    "                student_encoding_layers[i].load_state_dict(teacher_encoding_layers[i*2-1].state_dict())\n",
    "\n",
    "        elif init_method == 'Even Layer':\n",
    "            for i in range(len(student_encoding_layers)):\n",
    "                student_encoding_layers[i].load_state_dict(teacher_encoding_layers[i*2].state_dict())\n",
    "\n",
    "        else:\n",
    "            raise Exception(\"init_method is invalid. Select between 'Top-K Layer', 'Bottom-K Layer', 'Odd Layer', 'Even Layer'\")\n",
    "\n",
    "    # Else the part is a head or something else, copy the state_dict\n",
    "    else:\n",
    "        student.load_state_dict(teacher.state_dict())\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_types = ['Top-K Layer', 'Bottom-K Layer', 'Odd Layer', 'Even Layer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print('Teacher parameters :', count_parameters(teacher_model))\n",
    "\n",
    "for model_type in model_types:\n",
    "    model = type(teacher_model)(configuration)\n",
    "    model = distill_bert_weights(teacher=teacher_model, student=model, init_method=model_type)\n",
    "    print(f'Student ({model_type}) parameters :', count_parameters(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All student models have the same no. of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_parameters(model)/count_parameters(teacher_model) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#It has 40% less parameters than bert-base-uncased"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Loss function"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Softmax\n",
    "\n",
    "$$\n",
    "P_i(\\mathbf{z}_i, T) = \\frac{\\exp(\\mathbf{z}_i / T)}{\\sum_{q=0}^k \\exp(\\mathbf{z}_q / T)}\n",
    "$$\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Knowledge Distillation\n",
    "\n",
    "#### CE Loss\n",
    "$$\\mathcal{L}_\\text{CE} = -\\sum^N_{j=0}\\sum_{i=0}^k {y}_i^{(j)}\\log(P_i({v}_i^{(j)}, 1))$$\n",
    "\n",
    "#### KL Loss\n",
    "$$\\mathcal{L}_\\text{KD} = -\\sum^N_{j=0}\\sum_{i=0}^k P_i({z}_i^{(j)}, T) \\log (P_i({v}_i^{(j)}, T))$$\n",
    "\n",
    "#### Cosine Embedding Loss\n",
    "$$\\mathcal{L}_{\\text{cosine}}(x_1, x_2, y) = \\frac{1}{N} \\sum_{i=1}^{N} \\left(1 - y_i \\cdot \\cos(\\theta_i)\\right)$$\n",
    "\n",
    "<!-- $$\\mathcal{L} = \\lambda \\mathcal{L}_\\text{KD} + (1-\\lambda)\\mathcal{L}_\\text{CE}$$\n",
    " -->\n",
    "\n",
    "#### Total Loss\n",
    "$$\\mathcal{L} = \\mathcal{L}_\\text{KD} + \\mathcal{L}_\\text{CE} + \\mathcal{L}_{\\text{cosine}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class DistillKL(nn.Module):\n",
    "    \"\"\"\n",
    "    Distilling the Knowledge in a Neural Network\n",
    "    Compute the knowledge-distillation (KD) loss given outputs, labels.\n",
    "    \"Hyperparameters\": temperature and alpha\n",
    "\n",
    "    NOTE: the KL Divergence for PyTorch comparing the softmaxs of teacher\n",
    "    and student expects the input tensor to be log probabilities! \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(DistillKL, self).__init__()\n",
    "\n",
    "    def forward(self, output_student, output_teacher, temperature=1):\n",
    "        '''\n",
    "        Note: the output_student and output_teacher are logits \n",
    "        '''\n",
    "        T = temperature #.cuda()\n",
    "        \n",
    "        KD_loss = nn.KLDivLoss(reduction='batchmean')(\n",
    "            F.log_softmax(output_student/T, dim=-1),\n",
    "            F.softmax(output_teacher/T, dim=-1)\n",
    "        ) * T * T\n",
    "        \n",
    "        return KD_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_div = DistillKL()\n",
    "criterion_cos = nn.CosineEmbeddingLoss()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "lr = 5e-5\n",
    "\n",
    "#training hyperparameters\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_model = teacher_model.to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Learning rate scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_scheduler\n",
    "\n",
    "num_epochs = 3\n",
    "num_update_steps_per_epoch = len(train_dataloader)\n",
    "num_training_steps = num_epochs * num_update_steps_per_epoch\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "    name=\"linear\", \n",
    "    optimizer=optimizer, \n",
    "    num_warmup_steps=0, \n",
    "    num_training_steps=num_training_steps\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "# Get the metric function\n",
    "if task_name is not None:\n",
    "    metric = evaluate.load(\"glue\", task_name)\n",
    "else:\n",
    "    metric = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "model_scores = {}\n",
    "\n",
    "for model_type in model_types:\n",
    "\n",
    "    model = type(teacher_model)(configuration)\n",
    "    model = distill_bert_weights(teacher=teacher_model, student=model, init_method=model_type)\n",
    "    model = model.to(device)\n",
    "\n",
    "    print(f\"\\n===== {model_type} =====\")\n",
    "\n",
    "    progress_bar = tqdm(range(num_training_steps))\n",
    "    eval_metrics = 0\n",
    "\n",
    "    #training hyperparameters\n",
    "    optimizer = optim.Adam(params=model.parameters(), lr=lr)\n",
    "    lr_scheduler = get_scheduler(\n",
    "    name=\"linear\", \n",
    "    optimizer=optimizer, \n",
    "    num_warmup_steps=0, \n",
    "    num_training_steps=num_training_steps\n",
    "    )\n",
    "\n",
    "    # Lists to store losses for each epoch\n",
    "    train_losses = []\n",
    "    train_losses_cls = []\n",
    "    train_losses_div = []\n",
    "    train_losses_cos = []\n",
    "    eval_losses = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        teacher_model.eval()\n",
    "        train_loss = 0\n",
    "        train_loss_cls = 0\n",
    "        train_loss_div = 0\n",
    "        train_loss_cos = 0\n",
    "        \n",
    "        for batch in train_dataloader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            # compute student output\n",
    "            outputs = model(**batch) \n",
    "            # compute teacher output\n",
    "            with torch.no_grad():\n",
    "                output_teacher = teacher_model(**batch)\n",
    "\n",
    "            # assert size\n",
    "            assert outputs.logits.size() == output_teacher.logits.size()\n",
    "            \n",
    "            # cls loss \n",
    "            loss_cls  = outputs.loss\n",
    "            train_loss_cls += loss_cls.item()\n",
    "            # distillation loss\n",
    "            loss_div = criterion_div(outputs.logits, output_teacher.logits)\n",
    "            train_loss_div += loss_div.item()\n",
    "            # cosine loss\n",
    "            loss_cos = criterion_cos(output_teacher.logits, outputs.logits, torch.ones(output_teacher.logits.size()[0]).to(device))\n",
    "            train_loss_cos += loss_cos.item()\n",
    "            \n",
    "            # Average the loss and return it\n",
    "            loss = (loss_cls + loss_div + loss_cos) / 3\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            loss.backward()\n",
    "            # accelerator.backward(loss)\n",
    "            # Step with optimizer\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "            progress_bar.update(1)\n",
    "\n",
    "        train_losses.append(train_loss / len(train_dataloader))\n",
    "        train_losses_cls.append(train_loss_cls / len(train_dataloader))\n",
    "        train_losses_div.append(train_loss_div / len(train_dataloader))\n",
    "        train_losses_cos.append(train_loss_cos / len(train_dataloader))\n",
    "\n",
    "        print(f'Epoch at {epoch+1}: Train loss {train_loss/len(train_dataloader):.4f}:')\n",
    "        print(f'  - Loss_cls: {train_loss_cls/len(train_dataloader):.4f}')\n",
    "        print(f'  - Loss_div: {train_loss_div/len(train_dataloader):.4f}')\n",
    "        print(f'  - Loss_cos: {train_loss_cos/len(train_dataloader):.4f}')\n",
    "\n",
    "        model.eval()\n",
    "        eval_loss = 0\n",
    "        for batch in eval_dataloader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            with torch.no_grad():\n",
    "                outputs = model(**batch)\n",
    "                \n",
    "            loss_cls = outputs.loss\n",
    "            predictions = outputs.logits.argmax(dim=-1)\n",
    "\n",
    "            eval_loss += loss_cls.item()\n",
    "            # predictions, references = accelerator.gather((predictions, batch[\"labels\"]))\n",
    "            metric.add_batch(\n",
    "                predictions=predictions, \n",
    "                references=batch[\"labels\"])\n",
    "            \n",
    "        eval_metric = metric.compute()\n",
    "        eval_metrics += eval_metric['accuracy'] \n",
    "        eval_losses.append(eval_loss / len(eval_dataloader))  # Save the evaluation loss for plotting\n",
    "        \n",
    "        print(f\"Epoch at {epoch+1}: Test Acc {eval_metric['accuracy']:.4f}\")\n",
    "        \n",
    "    print('Avg Metric', eval_metrics/num_epochs)\n",
    "\n",
    "    model_scores[model_type] = {score_name: globals()[score_name] for score_name in [\n",
    "        'train_losses', 'train_losses_cls', 'train_losses_div', 'train_losses_cos', 'eval_losses'\n",
    "    ]}\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    progress_bar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Plotting\n",
    "epochs_list = range(1, num_epochs + 1)\n",
    "\n",
    "# set limit for y-axis of all subplots to max and min values of losses\n",
    "loss_types = ['train_losses', 'train_losses_cls', 'train_losses_div', 'train_losses_cos', 'eval_losses']\n",
    "y_upper_lim = max([loss for model_name in model_scores.keys()\n",
    "                   for loss_type in loss_types\n",
    "                   for loss in model_scores[model_name][loss_type]])\n",
    "y_lower_lim = min([loss for model_name in model_scores.keys()\n",
    "                   for loss_type in loss_types\n",
    "                   for loss in model_scores[model_name][loss_type]])\n",
    "\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "\n",
    "for i, model_name in enumerate(model_scores):\n",
    "    ax = fig.add_subplot(2, 2, i+1)\n",
    "    ax.plot(epochs_list, model_scores[model_name]['train_losses'], label='Total Train Loss')\n",
    "    ax.plot(epochs_list, model_scores[model_name]['train_losses_cls'], label='Train Loss_cls')\n",
    "    ax.plot(epochs_list, model_scores[model_name]['train_losses_div'], label='Train Loss_div')\n",
    "    ax.plot(epochs_list, model_scores[model_name]['train_losses_cos'], label='Train Loss_cos')\n",
    "    ax.plot(epochs_list, model_scores[model_name]['eval_losses'], label='Validation Loss')\n",
    "    ax.set_xlabel('Epochs')\n",
    "    ax.set_ylabel('Loss')\n",
    "    ax.set_title(model_name)\n",
    "    plt.legend()\n",
    "    plt.setp(ax, ylim=(y_lower_lim, y_upper_lim))\n",
    "\n",
    "fig.suptitle('Training and Validation Losses')\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appendix (Teacher Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "lr = 5e-5\n",
    "#training hyperparameters\n",
    "optimizer = optim.Adam(params=teacher_model.parameters(), lr=lr)\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "eval_metrics = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    teacher_model.train()\n",
    "    train_loss = 0\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        output_teacher = teacher_model(**batch)\n",
    "        # cls loss \n",
    "        loss = output_teacher.loss\n",
    "        train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        # accelerator.backward(loss)\n",
    "        # Step with optimizer\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)\n",
    "\n",
    "    print(f'Epoch at {epoch+1}: Train loss {train_loss/len(train_dataloader):.4f}:')\n",
    "    \n",
    "    teacher_model.eval()\n",
    "    for step, batch in enumerate(eval_dataloader):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = teacher_model(**batch)\n",
    "    \n",
    "        predictions = outputs.logits.argmax(dim=-1)\n",
    "        # predictions, references = accelerator.gather((predictions, batch[\"labels\"]))\n",
    "        metric.add_batch(\n",
    "            predictions=predictions, \n",
    "            references=batch[\"labels\"])\n",
    "        \n",
    "    eval_metric = metric.compute()\n",
    "    eval_metrics += eval_metric['accuracy'] \n",
    "    print(f\"Epoch at {epoch+1}: Test Acc {eval_metric['accuracy']:.4f}\")\n",
    "    \n",
    "print('Avg Metric', eval_metrics/num_epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
